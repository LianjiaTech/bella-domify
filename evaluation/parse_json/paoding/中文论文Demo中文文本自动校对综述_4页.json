{
    "document": [
        {
            "id": 122588,
            "uuid": "1e372d77-9511-11ef-8de2-00163e028884",
            "parsed": 2,
            "filename": "中文论文Demo中文文本自动校对综述_4页.pdf",
            "created_utc": 1730108622,
            "updated_utc": 1730108635,
            "exceptions": null
        }
    ],
    "pdf_page": [
        {
            "id": 822239,
            "did": 122588,
            "page": 3,
            "meta": {
                "width": 595,
                "height": 842,
                "page_type": null,
                "page_prob": null,
                "is_image": false
            },
            "created_utc": 1730108634,
            "updated_utc": 1730108634
        },
        {
            "id": 822238,
            "did": 122588,
            "page": 2,
            "meta": {
                "width": 595,
                "height": 842,
                "page_type": null,
                "page_prob": null,
                "is_image": false
            },
            "created_utc": 1730108634,
            "updated_utc": 1730108634
        },
        {
            "id": 822237,
            "did": 122588,
            "page": 1,
            "meta": {
                "width": 595,
                "height": 842,
                "page_type": null,
                "page_prob": null,
                "is_image": false
            },
            "created_utc": 1730108634,
            "updated_utc": 1730108634
        },
        {
            "id": 822236,
            "did": 122588,
            "page": 0,
            "meta": {
                "width": 595,
                "height": 842,
                "page_type": null,
                "page_prob": null,
                "is_image": false
            },
            "created_utc": 1730108634,
            "updated_utc": 1730108634
        }
    ],
    "pdf_elements": [
        {
            "page": 0,
            "elements": [
                {
                    "page": 0,
                    "text": "第36卷 第9期中文信息学报Vol.36,No.9",
                    "index": 0,
                    "syllabus": -1,
                    "element_type": "paragraphs",
                    "origin_index": 0
                },
                {
                    "page": 0,
                    "text": "2022年9月JOURNALOFCHINESEINFORMATIONPROCESSINGSep.,2022",
                    "index": 1,
                    "syllabus": -1,
                    "element_type": "paragraphs",
                    "origin_index": 1
                },
                {
                    "page": 0,
                    "text": "文章编号:1003-0077(2022)09-0001-18",
                    "index": 2,
                    "syllabus": -1,
                    "element_type": "paragraphs",
                    "origin_index": 2
                },
                {
                    "page": 0,
                    "text": "中文文本自动校对综述",
                    "index": 3,
                    "syllabus": -1,
                    "element_type": "paragraphs",
                    "origin_index": 3
                },
                {
                    "page": 0,
                    "text": "李云汉1,2,施运梅1,2,李 宁1,2,田英爱1,2",
                    "index": 4,
                    "syllabus": -1,
                    "element_type": "paragraphs",
                    "origin_index": 4
                },
                {
                    "page": 0,
                    "text": "(1.北京信息科技大学 网络文化与数字传播北京市重点实验室,北京 100101;",
                    "index": 5,
                    "syllabus": -1,
                    "element_type": "paragraphs",
                    "origin_index": 5
                },
                {
                    "page": 0,
                    "text": "2.北京信息科技大学 计算机学院,北京 100101)",
                    "index": 6,
                    "syllabus": -1,
                    "element_type": "paragraphs",
                    "origin_index": 6
                },
                {
                    "page": 0,
                    "text": "摘 要:文本校对在新闻发布、书刊出版、语音输入、汉字识别等领域有着极其重要的应用价值,是自然语言处理领域中的一个重要研究方向。该文对中文文本自动校对技术进行了系统性的梳理,将中文文本的错误类型分为拼写错误、语法错误和语义错误,并对这三类错误的校对方法进行了梳理,对中文文本自动校对的数据集和评价方法进行了总结,最后展望了中文文本自动校对技术的未来发展。",
                    "index": 7,
                    "syllabus": -1,
                    "element_type": "paragraphs",
                    "origin_index": 7
                },
                {
                    "page": 0,
                    "text": "关键词:自动校对;拼写错误;语法错误;语义错误;数据集;评估指标",
                    "index": 8,
                    "syllabus": -1,
                    "element_type": "paragraphs",
                    "origin_index": 8
                },
                {
                    "page": 0,
                    "text": "中图分类号:TP391 文献标识码:A",
                    "index": 9,
                    "syllabus": -1,
                    "element_type": "paragraphs",
                    "origin_index": 9
                },
                {
                    "page": 0,
                    "text": "ASurveyofAutomaticErrorCorrectionofChineseText",
                    "index": 10,
                    "syllabus": -1,
                    "element_type": "paragraphs",
                    "origin_index": 10
                },
                {
                    "page": 0,
                    "text": "LiYunhan1,2,ShiYunmei1,2,LiNing1,2,TianYingai1,2 (1.BeijingInformationScienceandTechnologyUniversity,BeijingKeyLaboratory ofInternetCultureDigitalDissemination,Beijing100101,China;",
                    "index": 11,
                    "syllabus": -1,
                    "element_type": "paragraphs",
                    "origin_index": 11
                },
                {
                    "page": 0,
                    "text": "2.SchoolofComputer,BeijingUniversityofInformationTechnology,Beijing100101,China)",
                    "index": 12,
                    "syllabus": 12,
                    "element_type": "paragraphs",
                    "origin_index": 12
                },
                {
                    "page": 0,
                    "text": "Abstract:Textcorrection,animportantresearchfieldin NaturalLanguage Processing (NLP),isofgreat applicationvalueinfieldssuchasnews,publication,andtextinput.Thispaperprovidesasystematicoverviewof automaticerrorcorrectiontechnologyforChinesetexts.ErrorsinChinesetextsaredividedintospellingerrors, grammaticerrorsandsemanticerrors,andthemethodsoferrorcorrectionforthesethreetypesarereviewed.More-over,datasetsandevaluationmethodsofautomaticerrorcorrectionforChinesetextsaresummarized.Intheend, prospectsfortheautomaticerrorcorrectionforChinesetextsareraised.",
                    "index": 13,
                    "syllabus": 12,
                    "element_type": "paragraphs",
                    "origin_index": 13
                },
                {
                    "page": 0,
                    "text": "Keywords:automaticcorrection;spellingerrors;grammaticalerrors;semanticerrors;datasets;evaluationindica-tors",
                    "index": 14,
                    "syllabus": 12,
                    "element_type": "paragraphs",
                    "origin_index": 14
                },
                {
                    "page": 0,
                    "text": "0 引言",
                    "index": 15,
                    "syllabus": 15,
                    "element_type": "paragraphs",
                    "origin_index": 15
                },
                {
                    "page": 0,
                    "text": "中文文本自动校对是自然语言处理技术的一个重要应用方面。随着互联网与信息技术的高速发展,中文文本数量呈爆炸式增长,这对传统的手工校对方式提出了严峻挑战。为了降低手工校对工作量,中文文本自动校对相关的研究工作得到了人们的重点关注。中文文本自动校对研究始于20世纪90年代,相对于英文文本自动校对研究开始较晚,但其发展速度快且取得了丰硕的研究成果,目前也出现了已经商业化的产品,如黑马校对软件、哈工大",
                    "index": 16,
                    "syllabus": 15,
                    "element_type": "paragraphs",
                    "origin_index": 16
                },
                {
                    "page": 0,
                    "text": "收稿日期:2021-10-07 定稿日期:2021-11-25",
                    "index": 17,
                    "syllabus": 15,
                    "element_type": "paragraphs",
                    "origin_index": 17
                },
                {
                    "page": 0,
                    "text": "基金项目:国家重点研发计划项目(2018YFB1004100)",
                    "index": 18,
                    "syllabus": 15,
                    "element_type": "footnotes",
                    "origin_index": 18
                },
                {
                    "page": 0,
                    "text": "讯飞实验室发布的飞鹰智能文本校对系统等。",
                    "index": 19,
                    "syllabus": 15,
                    "element_type": "paragraphs",
                    "origin_index": 19
                },
                {
                    "page": 0,
                    "text": "早期中文自动校对方法主要基于统计和规则相结合的方法[1-2],采用了分词、统计语言模型、统计机器翻译(StatisticalMachineTranslation,SMT)和混淆字符集等技术。随着深度学习的发展,一系列端到端的方法在自然语言处理(NaturalLanguageProcessing, NLP)领域逐渐得到应用,如循环神经网络(Recurrent NeuralNetwork,RNN)、序列到序列模型(Sequence-to-sequence,Seq2seq)[3-4]、注意力机制[5-6]、卷积序列到 序 列 模 型 (ConvolutionalSequencetoSequence, ConvS2S)[7] 和 基 于 自 注 意 力 的 Transformer 模型[8],中文文本自动校对研究逐渐从基于规则和统2中 文 信 息 学 报 2022年",
                    "index": 20,
                    "syllabus": 15,
                    "continued": true,
                    "element_type": "paragraphs",
                    "origin_index": 20
                }
            ]
        },
        {
            "page": 1,
            "elements": [
                {
                    "page": 1,
                    "text": "计语言模型相结合的方法转向基于深度模型的方法,并 且 使 用 序 列 标 注 模 型、神 经 机 器 翻 译 模 型(NeuralMachineTranslation,NMT)和预训练语言模型进行端到端的校对。",
                    "index": 0,
                    "syllabus": 15,
                    "element_type": "paragraphs",
                    "origin_index": 22
                },
                {
                    "page": 1,
                    "text": "本文概述了中文文本中的常见错误类型,分析了中文文本校对技术的研究发展现状,对中文文本校对共享任务数据集以及校对系统的评估指标进行了归纳总结,最后探讨了中文文本自动校对技术未来发展的方向。",
                    "index": 1,
                    "syllabus": 15,
                    "element_type": "paragraphs",
                    "origin_index": 23
                },
                {
                    "page": 1,
                    "text": "1 中文文本的错误类型",
                    "index": 2,
                    "syllabus": 23,
                    "element_type": "paragraphs",
                    "origin_index": 24
                },
                {
                    "page": 1,
                    "text": "中文文本产生的错误可大体分为拼写错误、语法错误和语义错误三类。",
                    "index": 3,
                    "syllabus": 23,
                    "element_type": "paragraphs",
                    "origin_index": 25
                },
                {
                    "page": 1,
                    "text": "拼写错误 张仰森等人[9-10]和 Liu等人[11]指出音似、形似字错误是中文文本中常见的拼写错误。形似字错误主要发生在五笔输入和字符识别(Optical CharacterRecognition,OCR)过程中,音似错误则主要发生在拼音输入和语音识别(AutomatedSpeechRec-ognition,ASR)过程中。其中,音似错误又可以进一步细分为同音同调、同音异调和相似音错误[12-13]。虽然大部分拼写错误是由音似、形似字误用导致,但也有些错误是由于缺少常识性知识或语言学知识所导致的,如表1所示。",
                    "index": 4,
                    "syllabus": 23,
                    "element_type": "paragraphs",
                    "origin_index": 26
                },
                {
                    "page": 1,
                    "text": "表1 常见拼写错误举例",
                    "index": 5,
                    "syllabus": 23,
                    "element_type": "paragraphs",
                    "origin_index": 27
                },
                {
                    "unit": "",
                    "cells": {
                        "0_0": {
                            "value": "错误类型"
                        },
                        "0_2": {
                            "value": "错误"
                        },
                        "0_3": {
                            "value": "正确"
                        },
                        "1_0": {
                            "value": "形似字错误"
                        },
                        "1_2": {
                            "value": "诞续"
                        },
                        "1_3": {
                            "value": "延续"
                        },
                        "2_0": {
                            "value": "音似\n字错\n误"
                        },
                        "2_1": {
                            "value": "同音\n同调"
                        },
                        "2_2": {
                            "value": "火势向四周漫(man4)延"
                        },
                        "2_3": {
                            "value": "火 势 向 四 周 蔓\n(man4)延"
                        },
                        "3_1": {
                            "value": "同音\n异调"
                        },
                        "3_2": {
                            "value": "但是 不 行 (xing2)还 是\n发生了"
                        },
                        "3_3": {
                            "value": "但是不幸(xing4)\n还是发生了"
                        },
                        "4_1": {
                            "value": "相似\n音"
                        },
                        "4_2": {
                            "value": "词青(qing1)标注"
                        },
                        "4_3": {
                            "value": "词性(xing2)标注"
                        },
                        "5_0": {
                            "value": "知识型错误"
                        },
                        "5_2": {
                            "value": "埃及有金子塔"
                        },
                        "5_3": {
                            "value": "埃及有金字塔"
                        },
                        "6_0": {
                            "value": "推断型错误"
                        },
                        "6_2": {
                            "value": "他的 求胜欲 很强,为了\n越狱在挖洞"
                        },
                        "6_3": {
                            "value": "他的求生欲很强,\n为了越狱在挖洞"
                        }
                    },
                    "index": 6,
                    "title": "表1 常见拼写错误举例",
                    "merged": [
                        [
                            [
                                0,
                                0
                            ],
                            [
                                0,
                                1
                            ]
                        ],
                        [
                            [
                                1,
                                0
                            ],
                            [
                                1,
                                1
                            ]
                        ],
                        [
                            [
                                2,
                                0
                            ],
                            [
                                3,
                                0
                            ],
                            [
                                4,
                                0
                            ]
                        ],
                        [
                            [
                                5,
                                0
                            ],
                            [
                                5,
                                1
                            ]
                        ],
                        [
                            [
                                6,
                                0
                            ],
                            [
                                6,
                                1
                            ]
                        ]
                    ],
                    "element_type": "tables",
                    "page": 1,
                    "origin_index": 28
                },
                {
                    "page": 1,
                    "text": "语法错误 NLPTEA 等[14-20]语法错误校对竞赛将中文文本常见语法错误归纳为字词冗余错误(Redundant words,R)、字 词 缺 失 错 误 (Missing words,M)、搭配不当错误(Selectionerrors,S)和字词乱 序 错 误 (Wordorderingerrors,W),如 表 2所示。",
                    "index": 7,
                    "syllabus": 23,
                    "element_type": "paragraphs",
                    "origin_index": 29
                },
                {
                    "page": 1,
                    "text": "表2 常见语法错误举例",
                    "index": 8,
                    "syllabus": 23,
                    "element_type": "paragraphs",
                    "origin_index": 30
                },
                {
                    "unit": "",
                    "cells": {
                        "0_0": {
                            "value": "错误\n类型"
                        },
                        "0_1": {
                            "value": "错误"
                        },
                        "0_2": {
                            "value": "正确"
                        },
                        "1_0": {
                            "value": "字词\n冗余"
                        },
                        "1_1": {
                            "value": "我根本不能理解这妇女\n辞职回家的现象。"
                        },
                        "1_2": {
                            "value": "我根本不能理解妇女辞职\n回家的现象。"
                        },
                        "2_0": {
                            "value": "字词\n缺失"
                        },
                        "2_1": {
                            "value": "我河边散步的时候。"
                        },
                        "2_2": {
                            "value": "我在河边散步的时候。"
                        },
                        "3_0": {
                            "value": "搭配\n不当"
                        },
                        "3_1": {
                            "value": "还 有 其 他 的 人 也 受\n被害。"
                        },
                        "3_2": {
                            "value": "还有其他的人也受伤害。"
                        },
                        "4_0": {
                            "value": "字词\n乱序"
                        },
                        "4_1": {
                            "value": "世界上每天由于饥饿很\n多人死亡。"
                        },
                        "4_2": {
                            "value": "世界上每天很多人由于饥\n饿死亡。"
                        }
                    },
                    "index": 9,
                    "title": "表2 常见语法错误举例",
                    "merged": [],
                    "element_type": "tables",
                    "page": 1,
                    "origin_index": 31
                },
                {
                    "page": 1,
                    "text": "语义错误 语义错误是指一些语言错误在字词层面和语法搭配上不存在问题,而是在语义层面上的搭配有误[21],如表3所示。由于语义错误的处理需要模型理解上下文的语义信息,因而对模型提出了较高的要求,其校对难度要高于拼写错误校对和语法错误校对。",
                    "index": 10,
                    "syllabus": 23,
                    "element_type": "paragraphs",
                    "origin_index": 32
                },
                {
                    "page": 1,
                    "text": "表3 常见语义错误举例",
                    "index": 11,
                    "syllabus": 23,
                    "element_type": "paragraphs",
                    "origin_index": 33
                },
                {
                    "unit": "",
                    "cells": {
                        "0_0": {
                            "value": "错误类型"
                        },
                        "0_1": {
                            "value": "错误"
                        },
                        "0_2": {
                            "value": "正确"
                        },
                        "1_0": {
                            "value": "知识错误"
                        },
                        "1_1": {
                            "value": "中国的首都是南京"
                        },
                        "1_2": {
                            "value": "中国的首都是北京"
                        },
                        "2_0": {
                            "value": "搭配错误"
                        },
                        "2_1": {
                            "value": "他戴着帽子和皮靴就\n出门了"
                        },
                        "2_2": {
                            "value": "他戴着帽子穿着皮靴就\n出门了"
                        }
                    },
                    "index": 12,
                    "title": "表3 常见语义错误举例",
                    "merged": [],
                    "element_type": "tables",
                    "page": 1,
                    "origin_index": 34
                },
                {
                    "page": 1,
                    "text": "下文中将分别对拼写错误、语法错误和语义错误的自动校对方法进行总结与分析。",
                    "index": 13,
                    "syllabus": 23,
                    "element_type": "paragraphs",
                    "origin_index": 35
                },
                {
                    "page": 1,
                    "text": "2 中文文本自动校对方法",
                    "index": 14,
                    "syllabus": 35,
                    "element_type": "paragraphs",
                    "origin_index": 36
                },
                {
                    "page": 1,
                    "text": "2.1 拼写错误校对方法",
                    "index": 15,
                    "syllabus": 36,
                    "element_type": "paragraphs",
                    "origin_index": 37
                },
                {
                    "page": 1,
                    "text": "中文文本拼写校对流程大致可以分为以下三步:①错误识别:判断文本是否存在拼写错误,并标记出错误位置;②生成纠正候选:利用混淆字符或通过模型生成字符等方法构建错误字符的纠正候选;③评估纠正候选:利用某种评分函数或分类器等,结合局部乃至全局特征对纠正候选排序,排序最高的纠正候选作为最终校对结果。事实上,大部分校对方法的流程都可以划分为上述三步,不过也有部分方法,如基于深度模型端到端的校对方法,将错误识别阶段省略,但本质上也属于此流程。",
                    "index": 16,
                    "syllabus": 36,
                    "element_type": "paragraphs",
                    "origin_index": 38
                },
                {
                    "page": 1,
                    "text": "2.1.1 基于规则和统计语言模型结合的校对方法",
                    "index": 17,
                    "syllabus": 38,
                    "element_type": "paragraphs",
                    "origin_index": 39
                },
                {
                    "page": 1,
                    "text": "中文拼写错误校对早期采用的主要是规则和统计语言模型(StatisticalLanguage Model,SLM)相结合的校对方法,该类方法使用规则和统计语言模型进行检错,在生成候选阶段利用混淆字符或通过9期 李云汉等:中文文本自动校对综述3",
                    "index": 18,
                    "syllabus": 38,
                    "continued": true,
                    "element_type": "paragraphs",
                    "origin_index": 40
                }
            ]
        },
        {
            "page": 2,
            "elements": [
                {
                    "page": 2,
                    "text": "模型生成字符的方式得到纠正候选字符,最后通过统计语言模型进行纠正候选的评估,其中,校对规则主要使用了 混 淆 字 符 集、基 于 分 词 的 查 错 规 则 和校对词典等,统计语言模型主要使用了 N 元语法(N-gram)、条 件 随 机 场 (Conditional Random Fields,CRF)等,如表4所示。",
                    "index": 0,
                    "syllabus": 41,
                    "continued": true,
                    "element_type": "paragraphs",
                    "origin_index": 42
                },
                {
                    "page": 2,
                    "text": "表4 基于规则和统计的拼写校对方法",
                    "index": 1,
                    "syllabus": 41,
                    "element_type": "paragraphs",
                    "origin_index": 44
                },
                {
                    "unit": "",
                    "cells": {
                        "0_0": {
                            "value": "引用"
                        },
                        "0_1": {
                            "value": "语言"
                        },
                        "0_2": {
                            "value": "规则"
                        },
                        "0_3": {
                            "value": "统计模型"
                        },
                        "1_0": {
                            "value": "[22],1995"
                        },
                        "1_1": {
                            "value": "繁体"
                        },
                        "1_2": {
                            "value": "混淆字符集"
                        },
                        "1_3": {
                            "value": "Bi-gram"
                        },
                        "2_0": {
                            "value": "[23],1998"
                        },
                        "2_1": {
                            "value": "简体"
                        },
                        "2_2": {
                            "value": "最长匹配分词"
                        },
                        "2_3": {
                            "value": "Tri-gram"
                        },
                        "3_0": {
                            "value": "[24],2001"
                        },
                        "3_1": {
                            "value": "简体"
                        },
                        "3_2": {
                            "value": "—"
                        },
                        "3_3": {
                            "value": "互信息"
                        },
                        "4_0": {
                            "value": "[25],2002"
                        },
                        "4_1": {
                            "value": ""
                        },
                        "4_2": {
                            "value": "混淆字符集,最小编辑距离"
                        },
                        "4_3": {
                            "value": "Tri-gram,贝叶斯分类器"
                        },
                        "5_0": {
                            "value": "[26],2006"
                        },
                        "5_1": {
                            "value": "简体"
                        },
                        "5_2": {
                            "value": "非多字词错误查错规则"
                        },
                        "5_3": {
                            "value": "互信息"
                        },
                        "6_0": {
                            "value": "[27],2012"
                        },
                        "6_1": {
                            "value": "繁体"
                        },
                        "6_2": {
                            "value": "形似字符集"
                        },
                        "6_3": {
                            "value": "Bi-gram,线性回归"
                        },
                        "7_0": {
                            "value": "[28],2013"
                        },
                        "7_1": {
                            "value": "繁体"
                        },
                        "7_2": {
                            "value": "混淆字符集"
                        },
                        "7_3": {
                            "value": "Bi-gram,线性回归"
                        },
                        "8_0": {
                            "value": "[29],2013"
                        },
                        "8_1": {
                            "value": "繁体"
                        },
                        "8_2": {
                            "value": "混淆字符集,E-HowNet"
                        },
                        "8_3": {
                            "value": "N-gram"
                        },
                        "9_0": {
                            "value": "[30],2013"
                        },
                        "9_1": {
                            "value": "繁体"
                        },
                        "9_2": {
                            "value": "混淆字符集,混淆字符替换规则"
                        },
                        "9_3": {
                            "value": "N-gram"
                        },
                        "10_0": {
                            "value": "[31],2013"
                        },
                        "10_1": {
                            "value": "繁体"
                        },
                        "10_2": {
                            "value": "混淆字符集,校对词典"
                        },
                        "10_3": {
                            "value": "Tri-gram,CRF"
                        },
                        "11_0": {
                            "value": "[32],2013"
                        },
                        "11_1": {
                            "value": "繁体"
                        },
                        "11_2": {
                            "value": "混淆字符集"
                        },
                        "11_3": {
                            "value": "N-gram"
                        },
                        "12_0": {
                            "value": "[33],2013"
                        },
                        "12_1": {
                            "value": "繁体"
                        },
                        "12_2": {
                            "value": "—"
                        },
                        "12_3": {
                            "value": "最大熵"
                        },
                        "13_0": {
                            "value": "[34],2013"
                        },
                        "13_1": {
                            "value": "繁体"
                        },
                        "13_2": {
                            "value": "混淆字符集,词典"
                        },
                        "13_3": {
                            "value": "SMT,N-gram,SVM"
                        },
                        "14_0": {
                            "value": "[35],2013"
                        },
                        "14_1": {
                            "value": "繁体"
                        },
                        "14_2": {
                            "value": "校对词典,检错规则"
                        },
                        "14_3": {
                            "value": "SMT,N-gram"
                        },
                        "15_0": {
                            "value": "[36],2014"
                        },
                        "15_1": {
                            "value": "繁体"
                        },
                        "15_2": {
                            "value": "混淆字符集"
                        },
                        "15_3": {
                            "value": "Tri-gram"
                        },
                        "16_0": {
                            "value": "[37],2014"
                        },
                        "16_1": {
                            "value": "繁体"
                        },
                        "16_2": {
                            "value": "混淆字符集"
                        },
                        "16_3": {
                            "value": "噪声信道模型,N-gram"
                        },
                        "17_0": {
                            "value": "[38],2014"
                        },
                        "17_1": {
                            "value": "繁体"
                        },
                        "17_2": {
                            "value": "校对规则"
                        },
                        "17_3": {
                            "value": "图模型,CRF"
                        },
                        "18_0": {
                            "value": "[39],2014"
                        },
                        "18_1": {
                            "value": "繁体"
                        },
                        "18_2": {
                            "value": "校对词典,编辑距离,最长匹配分词"
                        },
                        "18_3": {
                            "value": "HMM,N-gram,SVM"
                        },
                        "19_0": {
                            "value": "[40],2015"
                        },
                        "19_1": {
                            "value": "繁体"
                        },
                        "19_2": {
                            "value": "混淆字符集"
                        },
                        "19_3": {
                            "value": "CRF,N-gram"
                        },
                        "20_0": {
                            "value": "[41],2015"
                        },
                        "20_1": {
                            "value": "繁体"
                        },
                        "20_2": {
                            "value": "—"
                        },
                        "20_3": {
                            "value": "N-gram"
                        },
                        "21_0": {
                            "value": "[42],2016"
                        },
                        "21_1": {
                            "value": "简体"
                        },
                        "21_2": {
                            "value": "模式匹配,中文串相似度计算"
                        },
                        "21_3": {
                            "value": "N-gram"
                        },
                        "22_0": {
                            "value": "[43],2017"
                        },
                        "22_1": {
                            "value": "繁体"
                        },
                        "22_2": {
                            "value": "模式匹配,E-HowNet,混淆字符集"
                        },
                        "22_3": {
                            "value": "N-gram"
                        }
                    },
                    "index": 2,
                    "title": "表4 基于规则和统计的拼写校对方法",
                    "merged": [],
                    "element_type": "tables",
                    "page": 2,
                    "origin_index": 45
                },
                {
                    "page": 2,
                    "text": "对于规则和统计相结合的校对方法的研究,通常是改进校对流程的不同阶段的方法,可大致分为三类:",
                    "index": 3,
                    "syllabus": 41,
                    "element_type": "paragraphs",
                    "origin_index": 46
                },
                {
                    "page": 2,
                    "text": "错误识别阶段 基于统计语言模型的检错。基于统计语言模型的检错方法通常都需要先对原句进行分词,然后通过统计语言模型与词性标注序列等相结合的方式进行检错,其中统计语言模型主要用到 N-gram 等,如于勐等人[23]提出一种混合校对系统 HMCTC(HybridMethodforChineseTextCol-lation),采用最长匹配分词结合词典的方式将原句分词,然后以 Tri-gram 为基础结合语法属性标注进行检错,将相邻词共现频率低于阈值和语法序列标注不合理的地方标记为错误;张仰森等人[24]提出了一种基于互信息的字词接续判断模型,通过判断相邻字和相邻词的接续性进行检错。早期基于统计语言模型的检错方法通常都需要构建庞大的字字、词词同现频率库,这带来了严重的数据稀疏问题,造成这个问题的原因除了统计模型本身的缺陷外,还因为早期的检错方法没有深度地分析中文分词的特点。张仰森等人[26]通过分析中文文本的特点指出,中文文本大多由二字以上的词构成,分词后出现的连续单字词一般不超过5个,且出现的单字词多是助词、介词等,而含有拼写错误的文本分词后会出现连续的不合理的单字散串,并由此提出了“非多字词错误”,在检错时主要针对分词后出现的连续单字词进行判断,字字同现库通过正确文本中的连续单字词同现频率进行构建,减小了同现频率库的规模,缓解了数据稀疏问题;Xie等人[41]对文本中长度等于2和大 于 2 的 连 续 单 字 词 分 别 使 用 Bi-gram 和",
                    "index": 4,
                    "syllabus": 41,
                    "continued": true,
                    "element_type": "paragraphs",
                    "origin_index": 47
                }
            ]
        },
        {
            "page": 3,
            "elements": [
                {
                    "page": 3,
                    "text": "9期 李云汉等:中文文本自动校对综述13",
                    "index": 0,
                    "syllabus": 41,
                    "element_type": "paragraphs",
                    "origin_index": 49
                },
                {
                    "page": 3,
                    "text": "索,这些模型参数多、规模大、计算速度慢,难以满足搜索引擎搜索和语音交互等实时场景。如何在效果损失较小的情况下缩小模型规模、缩短迭代周期、加快预 测 速 度 是 一 个 重 要 的 研 究 方 向,如 Sanh 等人[105]提出了 LTD-BERT 模型(LearningtoDistill BERT)对 BERT 进行了模型压缩,在效果损失很小的基础上,降低了存储和运算开销。",
                    "index": 1,
                    "syllabus": 41,
                    "element_type": "paragraphs",
                    "origin_index": 50
                },
                {
                    "page": 3,
                    "text": "(3)现有的文本自动校对研究主要面向通用领域,随着无纸化办公的普及,针对不同领域具体场景下的文本校对需求迫在眉睫,将受到越来越多研究人员的关注。具体应用场景下的文本校对通常需要在传统校对的基础上进行更加有针对性的建模,以公文领域为例,张仰森等人[106]指出政治新闻领域存在的文本错误除常见的拼写、语法错误以外,还有领导人顺序错误和领导人姓名-职务对应错误等,针对政治新闻等领域的文本校对,需要分析领域错误特点,单独构建领域词典。",
                    "index": 2,
                    "syllabus": 41,
                    "element_type": "paragraphs",
                    "origin_index": 51
                },
                {
                    "page": 3,
                    "text": "(4)现阶段中文文本语法错误校对方法主要还是基于 Seq2Seq的 NMT 方法,通常生成模型需要大规模的平行语料进行训练,而语法纠错相关的语料则比较匮乏,因此如何自动构建大量中文语法校对训练语料将受到更多学者的关注。目前针对语法校对训练数据不足的问题,部分英文语法校对的研究者提出通过构造伪数据的方法来增加训练数据,如 Ge等人[107]将正确语句输入 Seq2Seq,将错误语句作为 输 出,训 练 得 到 一 个 错 误 语 句 生 成 模 型;Lichtarge等人[108]使用翻译系统将英文翻译成一种中间语言,如日语、法语等,再将中间语言翻译回英文,生成的英语语义和原始英语语句基本保持不变,但是往往会存在一些语法错误。中文语法校对也可以参考上述办法构造大规模平行语料。",
                    "index": 3,
                    "syllabus": 41,
                    "element_type": "paragraphs",
                    "origin_index": 52
                },
                {
                    "page": 3,
                    "text": "(5)语义问题的研究一直是 NLP研究中的薄弱环节,也是中文文本校对的难点[95],已有的语义错误校对方法主要是基于规则、知识库和语义推理的方法[21,96,98]。基于规则、知识库等的校对方法需要人工建立规则,整理领域词典,不适用于大规模的语义错误校对,随着深度学习的不断发展,如何通过深度学习的方法解决语义错误会持续受到学者们的关注。",
                    "index": 4,
                    "syllabus": 41,
                    "element_type": "paragraphs",
                    "origin_index": 53
                },
                {
                    "page": 3,
                    "text": "中文文本自动校对作为自然语言处理领域一个重要研究方向,一直以来受到相当广泛的关注。本文主要阐述了中文文本拼写错误和语法错误的校对方法,整理了相关共享任务数据集,并对未来的研究方向进行了分析和展望。",
                    "index": 5,
                    "syllabus": 41,
                    "continued": true,
                    "element_type": "paragraphs",
                    "origin_index": 54
                },
                {
                    "page": 3,
                    "text": "参考文献",
                    "index": 6,
                    "syllabus": 55,
                    "element_type": "paragraphs",
                    "origin_index": 56
                },
                {
                    "page": 3,
                    "text": "[1] 徐连诚,石磊.自动文字校对动态规划算法的设计与实现[J].计算机科学,2002,29(9):149-150.",
                    "index": 7,
                    "syllabus": 55,
                    "element_type": "paragraphs",
                    "origin_index": 57
                },
                {
                    "page": 3,
                    "text": "[2] 龚小谨,罗振声,骆卫华.中文文本自动校对中的语法错误检 查 [J].计 算 机 工 程 与 应 用,2003,39(8):98-100.",
                    "index": 8,
                    "syllabus": 55,
                    "element_type": "paragraphs",
                    "origin_index": 58
                },
                {
                    "page": 3,
                    "text": "[3] ChoK,VanMerrienboerB,GulcehreC,etal.Learn-ingphraserepresentationsusingRNNencoder-decoder forstatisticalmachinetranslation[C]//Proceedingsof theConferenceonEmpiricalMethodsinNaturalLan-guageProcessing.Stroudsburg,PA,USA:Associa-tionforComputationalLinguistics,2014:1724-1734.",
                    "index": 9,
                    "syllabus": 55,
                    "element_type": "paragraphs",
                    "origin_index": 59
                },
                {
                    "page": 3,
                    "text": "[4] SutskeverI,VinyalsO,LeQV.Sequencetosequence learningwithneuralnetworks[C]//Proceddingsofthe 27thInternationalConferenceon NeuralInformation ProcessingSystems.Cambridge,USA:MIT Press, 2014:3104-3112.",
                    "index": 10,
                    "syllabus": 55,
                    "element_type": "paragraphs",
                    "origin_index": 60
                },
                {
                    "page": 3,
                    "text": "[5] BahdanauD,ChoK,BengioY.Neuralmachinetrans-lationbyjointlylearningtoalignandtranslate[C]//Proceedingsof3rdInternationalConferenceonLearn-ingRepresentations.SanDiego,UnitedStates:Inter-national Conference on Learning Representations, 2015:940-1000.",
                    "index": 11,
                    "syllabus": 55,
                    "element_type": "paragraphs",
                    "origin_index": 61
                },
                {
                    "page": 3,
                    "text": "[6] LuongT,Pham H,ManningCD.Effectiveapproa-ches to attention-based neural machine translation[C]//Proceedings ofthe Conference on Empirical Methodsin Natural Language Processing.Strouds-burg,PA,USA:AssociationforComputationalLin-guistics,2015:1412-1421.",
                    "index": 12,
                    "syllabus": 55,
                    "element_type": "paragraphs",
                    "origin_index": 62
                },
                {
                    "page": 3,
                    "text": "[7] GehringJ,AuliM,GrangierD,etal.Convolutional sequencetosequencelearning[C]//Proceedingsofthe 34thInternationalConferenceon Machine Learning. UnitedStates:JMLR,2017:2029-2042.",
                    "index": 13,
                    "syllabus": 55,
                    "element_type": "paragraphs",
                    "origin_index": 63
                },
                {
                    "page": 3,
                    "text": "[8] VaswaniA,ShazeerN,ParmarN,etal.Attentionis allyouneed[C]//Proceedingsofthe31stInternational ConferenceonNeuralInformationProcessingSystems. RedHook,NY,USA:CurranAssociatesInc,2017: 6000-6010.",
                    "index": 14,
                    "syllabus": 55,
                    "element_type": "paragraphs",
                    "origin_index": 64
                },
                {
                    "page": 3,
                    "text": "[9] 张仰森、丁冰青.中文文本自动校对技术现状及展望[J].中文信息学报,1998(301):51-57.",
                    "index": 15,
                    "syllabus": 55,
                    "element_type": "paragraphs",
                    "origin_index": 65
                },
                {
                    "page": 3,
                    "text": "[10] 张仰森,俞士汶.文本自动校对技术研究综述[J].计算机应用研究,2006,23(6):8-12.",
                    "index": 16,
                    "syllabus": 55,
                    "element_type": "paragraphs",
                    "origin_index": 66
                },
                {
                    "page": 3,
                    "text": "[11] LiuCL,LaiM H,TienK W,etal.Visuallyand phonologicallysimilarcharactersinincorrectChinese words[J].ACM TransactionsonAsianLanguageIn-formationProcessing,2011,10(2):1-39.",
                    "index": 17,
                    "syllabus": 55,
                    "element_type": "paragraphs",
                    "origin_index": 67
                }
            ]
        }
    ],
    "pdf_stamps": [],
    "syllabus": {
        "index": -1,
        "children": [
            {
                "page": 0,
                "etype": "paragraphs",
                "index": 12,
                "level": 1,
                "range": [
                    12,
                    68
                ],
                "title": "2.SchoolofComputer,BeijingUniversityofInformationTechnology,Beijing100101,China)",
                "parent": -1,
                "element": 12,
                "children": [
                    {
                        "page": 0,
                        "etype": "paragraphs",
                        "index": 15,
                        "level": 2,
                        "range": [
                            15,
                            24
                        ],
                        "title": "0 引言",
                        "parent": 12,
                        "element": 15,
                        "children": []
                    },
                    {
                        "page": 1,
                        "etype": "paragraphs",
                        "index": 23,
                        "level": 2,
                        "range": [
                            24,
                            36
                        ],
                        "title": "1 中文文本的错误类型",
                        "parent": 12,
                        "element": 24,
                        "children": []
                    },
                    {
                        "page": 1,
                        "etype": "paragraphs",
                        "index": 35,
                        "level": 2,
                        "range": [
                            36,
                            42
                        ],
                        "title": "2 中文文本自动校对方法",
                        "parent": 12,
                        "element": 36,
                        "children": [
                            {
                                "page": 1,
                                "etype": "paragraphs",
                                "index": 36,
                                "level": 3,
                                "range": [
                                    37,
                                    42
                                ],
                                "title": "2.1 拼写错误校对方法",
                                "parent": 35,
                                "element": 37,
                                "children": [
                                    {
                                        "page": 1,
                                        "etype": "paragraphs",
                                        "index": 38,
                                        "level": 4,
                                        "range": [
                                            39,
                                            42
                                        ],
                                        "title": "2.1.1 基于规则和统计语言模型结合的校对方法",
                                        "parent": 36,
                                        "element": 39,
                                        "children": []
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "page": 2,
                        "etype": "paragraphs",
                        "index": 41,
                        "level": 2,
                        "range": [
                            42,
                            56
                        ],
                        "title": "模型生成字符的方式得到纠正候选字符,最后通过统计语言模型进行纠正候选的评估,其中,校对规则主要使用了 混 淆 字 符 集、基 于 分 词 的 查 错 规 则 和",
                        "parent": 12,
                        "element": 42,
                        "children": []
                    },
                    {
                        "page": 3,
                        "etype": "paragraphs",
                        "index": 55,
                        "level": 2,
                        "range": [
                            56,
                            68
                        ],
                        "title": "参考文献",
                        "parent": 12,
                        "element": 56,
                        "children": []
                    }
                ]
            }
        ]
    }
}